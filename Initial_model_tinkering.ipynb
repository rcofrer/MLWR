{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Initial model tinkering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5_rRzfp-mCr"
      },
      "source": [
        "# usual imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTDeJkWpJ8Vt",
        "outputId": "e84a480d-2e8b-4620-ed8b-f6b0c3082913"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE-MmNyj_9-V"
      },
      "source": [
        "And yep, loading is indeed faster than using CSVs in this case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsWjWp3z-mDJ"
      },
      "source": [
        "with open('/content/gdrive/My Drive/Notebooks Colab/cleanDF.pickle', 'rb') as handle:\n",
        "    df = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKNBulemDjzq"
      },
      "source": [
        "X = df.copy().drop('HasDetections', 1)\n",
        "y = df.copy()['HasDetections']\n",
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swV0RgFnAECi"
      },
      "source": [
        "Now the actual model tinkering:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ObQ2FgqGQnV"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "categoricalColumns = list(X.select_dtypes(include='category').columns)\n",
        "numericalColumns = list(X.select_dtypes(exclude='category').columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wauPVJGkJ3us"
      },
      "source": [
        "Normalization and further preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9mImR64J665"
      },
      "source": [
        "for column in numericalColumns:\n",
        "    X[column] = ((X[column] - np.mean(X[column])) / np.std(X[column])).astype('float64')\n",
        "\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.01, stratify=y, random_state=11)\n",
        "\n",
        "uniques = {}\n",
        "for column in categoricalColumns:\n",
        "    uniques[column] = X[column].unique()\n",
        "\n",
        "uniquesDF = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in uniques.items() ]))\n",
        "\n",
        "categoricalEncoder = OneHotEncoder(handle_unknown='ignore', dtype='uint8', sparse=True)\n",
        "categoricalEncoder.fit(uniquesDF.astype(str))\n",
        "\n",
        "xTestNumerical = xTest[numericalColumns].values\n",
        "xTestCategorical = xTest[categoricalColumns]\n",
        "xTestCategorical = categoricalEncoder.transform(xTestCategorical)\n",
        "xTest = np.concatenate([xTestNumerical, scipy.sparse.csr_matrix.toarray(xTestCategorical)], axis=1)\n",
        "del xTestNumerical\n",
        "del xTestCategorical\n",
        "del uniquesDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb4Qo_yxLGQN"
      },
      "source": [
        "Training stuff:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqeeX5mQR_yc"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dA1WBuGADR0",
        "outputId": "ef0cd691-b832-4dc2-d927-98b174ac8f4e"
      },
      "source": [
        "model = SGDClassifier(loss='log', verbose=False)\n",
        "\n",
        "def iterateMiniBatches(inputs, targets, batchSize, shuffle=False):\n",
        "    assert inputs.shape[0] == targets.shape[0]\n",
        "    if shuffle:\n",
        "        indices = np.arange(inputs.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "    for start_idx in range(0, inputs.shape[0] - batchSize + 1, batchSize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchSize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchSize)\n",
        "        yield inputs.iloc[excerpt], targets.iloc[excerpt]\n",
        "\n",
        "classes = y.unique()\n",
        "\n",
        "numEpochs = 10\n",
        "batchSize = 2**10\n",
        "numBatches = xTrain.shape[0] // batchSize\n",
        "\n",
        "for n in range(numEpochs):\n",
        "    batchCounter = 0\n",
        "    print(f\"---------------------- EPOCH {n + 1} ----------------------\")\n",
        "    for batch in iterateMiniBatches(xTrain, yTrain, batchSize, shuffle=True):\n",
        "        batchCounter += 1\n",
        "        xBatch, yBatch = batch\n",
        "        xBatchNumerical = xBatch[numericalColumns].values\n",
        "        xBatchCategorical = xBatch[categoricalColumns]\n",
        "        xBatchCategorical = categoricalEncoder.transform(xBatchCategorical)\n",
        "        xBatch = np.concatenate([xBatchNumerical, scipy.sparse.csr_matrix.toarray(xBatchCategorical)], axis=1)\n",
        "        model.partial_fit(xBatch, yBatch, classes=classes)\n",
        "        if batchCounter % 200 == 0:\n",
        "            print(f\"Training batch number {batchCounter} out of {numBatches}\")\n",
        "            print(\"Batch score: %0.3f\" % model.score(xBatch, yBatch))\n",
        "            print(\"Test score: %0.3f\" % model.score(xTest, yTest))   \n",
        "    with open(f'/content/gdrive/My Drive/Notebooks Colab/logRegModel_e{n + 1}.pickle', 'wb') as handle:\n",
        "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        print(\"Model saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------- EPOCH 1 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.599\n",
            "Test score: 0.562\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.576\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.604\n",
            "Test score: 0.560\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.588\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.598\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.596\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.600\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.588\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.588\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.601\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.600\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.606\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.601\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.658\n",
            "Test score: 0.597\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.607\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.658\n",
            "Test score: 0.606\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.607\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.635\n",
            "Test score: 0.603\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.604\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.606\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.611\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.614\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.671\n",
            "Test score: 0.613\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.614\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.602\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.606\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.612\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.612\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.625\n",
            "Test score: 0.609\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.657\n",
            "Test score: 0.607\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.603\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.613\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.618\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.615\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.612\n",
            "Test score: 0.608\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.611\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.612\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.616\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.614\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.613\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.616\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.604\n",
            "Test score: 0.614\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.611\n",
            "Model saved\n",
            "---------------------- EPOCH 2 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.614\n",
            "Test score: 0.603\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.605\n",
            "Test score: 0.614\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.616\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.614\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.616\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.617\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.612\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.614\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.615\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.613\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.613\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.616\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.616\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.611\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.619\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.614\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.617\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.640\n",
            "Test score: 0.617\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.617\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.611\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.615\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.619\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.606\n",
            "Test score: 0.620\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.617\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.617\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.617\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.618\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.644\n",
            "Test score: 0.614\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.618\n",
            "Test score: 0.612\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.618\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.611\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.613\n",
            "Test score: 0.612\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.616\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.617\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.616\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.616\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.617\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.613\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.612\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.618\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.614\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.619\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.616\n",
            "Model saved\n",
            "---------------------- EPOCH 3 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.617\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.614\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.605\n",
            "Test score: 0.617\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.617\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.615\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.618\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.616\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.635\n",
            "Test score: 0.618\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.616\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.618\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.640\n",
            "Test score: 0.618\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.617\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.618\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.616\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.614\n",
            "Test score: 0.617\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.617\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.616\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.661\n",
            "Test score: 0.619\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.655\n",
            "Test score: 0.616\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.619\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.619\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.619\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.614\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.616\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.617\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.619\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.617\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.613\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.607\n",
            "Test score: 0.618\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.620\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.607\n",
            "Test score: 0.614\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.614\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.618\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.617\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.618\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.620\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.617\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.618\n",
            "Test score: 0.618\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.619\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.605\n",
            "Test score: 0.618\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.614\n",
            "Test score: 0.618\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.600\n",
            "Test score: 0.618\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.613\n",
            "Test score: 0.617\n",
            "Model saved\n",
            "---------------------- EPOCH 4 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.616\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.620\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.614\n",
            "Test score: 0.620\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.614\n",
            "Test score: 0.618\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.619\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.618\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.617\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.620\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.619\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.608\n",
            "Test score: 0.619\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.617\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.598\n",
            "Test score: 0.617\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.619\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.619\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.618\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.635\n",
            "Test score: 0.618\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.617\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.599\n",
            "Test score: 0.618\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.619\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.620\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.618\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.606\n",
            "Test score: 0.619\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.619\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.618\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.620\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.620\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.617\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.619\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.619\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.619\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.619\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.619\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.617\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.660\n",
            "Test score: 0.616\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.620\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.619\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.621\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.618\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.618\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.619\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.620\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.619\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.618\n",
            "Model saved\n",
            "---------------------- EPOCH 5 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.616\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.605\n",
            "Test score: 0.619\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.610\n",
            "Test score: 0.620\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.602\n",
            "Test score: 0.620\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.617\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.613\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.619\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.618\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.635\n",
            "Test score: 0.618\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.617\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.618\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.618\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.618\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.601\n",
            "Test score: 0.621\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.620\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.610\n",
            "Test score: 0.618\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.618\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.635\n",
            "Test score: 0.620\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.599\n",
            "Test score: 0.621\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.617\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.620\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.619\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.612\n",
            "Test score: 0.620\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.617\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.618\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.620\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.610\n",
            "Test score: 0.619\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.605\n",
            "Test score: 0.621\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.620\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.617\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.596\n",
            "Test score: 0.620\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.620\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.619\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.604\n",
            "Test score: 0.621\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.617\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.617\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.622\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.589\n",
            "Test score: 0.621\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.620\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.619\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.619\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.604\n",
            "Test score: 0.616\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.620\n",
            "Model saved\n",
            "---------------------- EPOCH 6 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.644\n",
            "Test score: 0.619\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.619\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.618\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.619\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.614\n",
            "Test score: 0.620\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.622\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.632\n",
            "Test score: 0.619\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.621\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.617\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.608\n",
            "Test score: 0.620\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.618\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.619\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.619\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.619\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.618\n",
            "Test score: 0.617\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.619\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.622\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.621\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.597\n",
            "Test score: 0.619\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.620\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.619\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.620\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.620\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.619\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.602\n",
            "Test score: 0.619\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.620\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.644\n",
            "Test score: 0.619\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.597\n",
            "Test score: 0.619\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.590\n",
            "Test score: 0.618\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.613\n",
            "Test score: 0.619\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.620\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.612\n",
            "Test score: 0.619\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.620\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.620\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.617\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.607\n",
            "Test score: 0.619\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.619\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.621\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.610\n",
            "Test score: 0.618\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.619\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.621\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.620\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.618\n",
            "Test score: 0.619\n",
            "Model saved\n",
            "---------------------- EPOCH 7 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.619\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.587\n",
            "Test score: 0.622\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.619\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.600\n",
            "Test score: 0.621\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.619\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.618\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.619\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.620\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.620\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.619\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.595\n",
            "Test score: 0.619\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.610\n",
            "Test score: 0.620\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.619\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.620\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.619\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.619\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.620\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.597\n",
            "Test score: 0.620\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.619\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.599\n",
            "Test score: 0.621\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.619\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.619\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.632\n",
            "Test score: 0.619\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.620\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.612\n",
            "Test score: 0.620\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.621\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.596\n",
            "Test score: 0.619\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.621\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.587\n",
            "Test score: 0.621\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.622\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.620\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.621\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.619\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.600\n",
            "Test score: 0.618\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.617\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.610\n",
            "Test score: 0.621\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.619\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.587\n",
            "Test score: 0.619\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.619\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.621\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.619\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.620\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.621\n",
            "Model saved\n",
            "---------------------- EPOCH 8 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.620\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.621\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.618\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.620\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.621\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.621\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.619\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.609\n",
            "Test score: 0.621\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.607\n",
            "Test score: 0.621\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.612\n",
            "Test score: 0.617\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.604\n",
            "Test score: 0.618\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.620\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.620\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.620\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.621\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.620\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.621\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.607\n",
            "Test score: 0.619\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.621\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.618\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.621\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.603\n",
            "Test score: 0.620\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.618\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.620\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.620\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.621\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.588\n",
            "Test score: 0.621\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.621\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.621\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.608\n",
            "Test score: 0.620\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.632\n",
            "Test score: 0.619\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.620\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.621\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.621\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.620\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.622\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.619\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.613\n",
            "Test score: 0.619\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.620\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.620\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.635\n",
            "Test score: 0.620\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.620\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.610\n",
            "Test score: 0.620\n",
            "Model saved\n",
            "---------------------- EPOCH 9 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.632\n",
            "Test score: 0.618\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.619\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.620\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.608\n",
            "Test score: 0.621\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.603\n",
            "Test score: 0.620\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.613\n",
            "Test score: 0.621\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.597\n",
            "Test score: 0.621\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.619\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.622\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.621\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.620\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.621\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.620\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.602\n",
            "Test score: 0.617\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.619\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.621\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.619\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.620\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.620\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.620\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.622\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.620\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.620\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.621\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.620\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.604\n",
            "Test score: 0.620\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.619\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.621\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.620\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.620\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.622\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.625\n",
            "Test score: 0.621\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.620\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.623\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.621\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.622\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.620\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.612\n",
            "Test score: 0.620\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.617\n",
            "Test score: 0.620\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.620\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.632\n",
            "Test score: 0.621\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.605\n",
            "Test score: 0.622\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.600\n",
            "Test score: 0.621\n",
            "Model saved\n",
            "---------------------- EPOCH 10 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.620\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.608\n",
            "Test score: 0.620\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.618\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.602\n",
            "Test score: 0.621\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.621\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.619\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.619\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.621\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.598\n",
            "Test score: 0.621\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.621\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.620\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.623\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.621\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.621\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.621\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.624\n",
            "Test score: 0.620\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.621\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.618\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.625\n",
            "Test score: 0.620\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.621\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.615\n",
            "Test score: 0.621\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.620\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.611\n",
            "Test score: 0.621\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.621\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.618\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.620\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.619\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.621\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.619\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.623\n",
            "Test score: 0.620\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.620\n",
            "Test score: 0.619\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.622\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.620\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.588\n",
            "Test score: 0.621\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.603\n",
            "Test score: 0.618\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.620\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.625\n",
            "Test score: 0.619\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.602\n",
            "Test score: 0.620\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.625\n",
            "Test score: 0.620\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.620\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.621\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.627\n",
            "Test score: 0.621\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.640\n",
            "Test score: 0.620\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yqzoStR6BP"
      },
      "source": [
        "# Neural net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N1UIonU-LzfT",
        "outputId": "70e4cc8f-ef47-4ff1-a7d0-3f1b2f14de69"
      },
      "source": [
        "numEpochs = 10\n",
        "batchSize = 2**10\n",
        "numBatches = xTrain.shape[0] // batchSize\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=1024, activation='relu', solver='adam', alpha=1e-4, batch_size=batchSize, max_iter=1)\n",
        "\n",
        "def iterateMiniBatches(inputs, targets, batchSize, shuffle=False):\n",
        "    assert inputs.shape[0] == targets.shape[0]\n",
        "    if shuffle:\n",
        "        indices = np.arange(inputs.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "    for start_idx in range(0, inputs.shape[0] - batchSize + 1, batchSize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchSize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchSize)\n",
        "        yield inputs.iloc[excerpt], targets.iloc[excerpt]\n",
        "\n",
        "classes = y.unique()\n",
        "\n",
        "for n in range(numEpochs):\n",
        "    batchCounter = 0\n",
        "    print(f\"---------------------- EPOCH {n + 1} ----------------------\")\n",
        "    for batch in iterateMiniBatches(xTrain, yTrain, batchSize, shuffle=True):\n",
        "        batchCounter += 1\n",
        "        xBatch, yBatch = batch\n",
        "        xBatchNumerical = xBatch[numericalColumns].values\n",
        "        xBatchCategorical = xBatch[categoricalColumns]\n",
        "        xBatchCategorical = categoricalEncoder.transform(xBatchCategorical)\n",
        "        xBatch = np.concatenate([xBatchNumerical, scipy.sparse.csr_matrix.toarray(xBatchCategorical)], axis=1)\n",
        "        model.partial_fit(xBatch, yBatch, classes=classes)\n",
        "        if batchCounter % 200 == 0:\n",
        "            print(f\"Training batch number {batchCounter} out of {numBatches}\")\n",
        "            print(\"Batch score: %0.3f\" % model.score(xBatch, yBatch))\n",
        "            print(\"Test score: %0.3f\" % model.score(xTest, yTest))   \n",
        "    with open(f'/content/gdrive/My Drive/Notebooks Colab/MLPModel_e{n + 1}.pickle', 'wb') as handle:\n",
        "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        print(\"Model saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------- EPOCH 1 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.622\n",
            "Test score: 0.624\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.625\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.606\n",
            "Test score: 0.629\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.629\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.630\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.632\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.635\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.634\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.636\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.635\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.637\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.639\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.640\n",
            "Test score: 0.639\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.640\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.640\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.641\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.642\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.642\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.643\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.642\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.667\n",
            "Test score: 0.643\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.659\n",
            "Test score: 0.644\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.643\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.640\n",
            "Test score: 0.647\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.621\n",
            "Test score: 0.644\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.644\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.645\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.629\n",
            "Test score: 0.644\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.644\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.645\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.645\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.625\n",
            "Test score: 0.645\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.645\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.646\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.645\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.680\n",
            "Test score: 0.643\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.645\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.646\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.662\n",
            "Test score: 0.648\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.646\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.646\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.646\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.648\n",
            "Model saved\n",
            "---------------------- EPOCH 2 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.648\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.648\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.647\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.632\n",
            "Test score: 0.649\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.645\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.657\n",
            "Test score: 0.649\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.648\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.648\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.644\n",
            "Test score: 0.647\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.648\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.650\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.647\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.650\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.648\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.647\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.649\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.670\n",
            "Test score: 0.650\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.616\n",
            "Test score: 0.649\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.649\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.648\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.650\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.684\n",
            "Test score: 0.649\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.650\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.648\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.668\n",
            "Test score: 0.649\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.626\n",
            "Test score: 0.648\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.662\n",
            "Test score: 0.649\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.650\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.650\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.661\n",
            "Test score: 0.649\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.649\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.649\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.636\n",
            "Test score: 0.649\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.661\n",
            "Test score: 0.649\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.640\n",
            "Test score: 0.649\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.662\n",
            "Test score: 0.648\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.648\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.680\n",
            "Test score: 0.648\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.649\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.640\n",
            "Test score: 0.651\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.650\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.650\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.650\n",
            "Model saved\n",
            "---------------------- EPOCH 3 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.644\n",
            "Test score: 0.649\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.650\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.662\n",
            "Test score: 0.650\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.647\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.659\n",
            "Test score: 0.649\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.649\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.675\n",
            "Test score: 0.650\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.650\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.684\n",
            "Test score: 0.649\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.661\n",
            "Test score: 0.649\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.638\n",
            "Test score: 0.649\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.672\n",
            "Test score: 0.650\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.661\n",
            "Test score: 0.648\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.649\n",
            "Test score: 0.650\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.649\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.661\n",
            "Test score: 0.650\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.657\n",
            "Test score: 0.649\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.633\n",
            "Test score: 0.649\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.651\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.650\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.628\n",
            "Test score: 0.648\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.659\n",
            "Test score: 0.651\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.659\n",
            "Test score: 0.650\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.651\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.649\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.662\n",
            "Test score: 0.649\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.668\n",
            "Test score: 0.650\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.637\n",
            "Test score: 0.649\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.672\n",
            "Test score: 0.651\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.650\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.651\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.657\n",
            "Test score: 0.651\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.651\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.658\n",
            "Test score: 0.651\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.651\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.650\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.641\n",
            "Test score: 0.650\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.667\n",
            "Test score: 0.651\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.668\n",
            "Test score: 0.652\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.631\n",
            "Test score: 0.651\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.651\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.652\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.650\n",
            "Model saved\n",
            "---------------------- EPOCH 4 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.658\n",
            "Test score: 0.650\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.677\n",
            "Test score: 0.651\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.652\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.677\n",
            "Test score: 0.649\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.665\n",
            "Test score: 0.649\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.651\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.655\n",
            "Test score: 0.650\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.653\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.655\n",
            "Test score: 0.649\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.651\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.652\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.651\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.651\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.651\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.656\n",
            "Test score: 0.651\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.655\n",
            "Test score: 0.652\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.651\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.674\n",
            "Test score: 0.651\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.652\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.654\n",
            "Test score: 0.651\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.652\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.662\n",
            "Test score: 0.652\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.647\n",
            "Test score: 0.652\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.651\n",
            "Test score: 0.651\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.645\n",
            "Test score: 0.650\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.652\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.679\n",
            "Test score: 0.652\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.665\n",
            "Test score: 0.650\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.649\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.652\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.672\n",
            "Test score: 0.651\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.655\n",
            "Test score: 0.651\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.658\n",
            "Test score: 0.651\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.651\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.651\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.688\n",
            "Test score: 0.652\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.650\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.687\n",
            "Test score: 0.649\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.659\n",
            "Test score: 0.651\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.652\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.668\n",
            "Test score: 0.652\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.679\n",
            "Test score: 0.651\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.670\n",
            "Test score: 0.650\n",
            "Model saved\n",
            "---------------------- EPOCH 5 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.650\n",
            "Test score: 0.651\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.605\n",
            "Test score: 0.651\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.651\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.650\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.660\n",
            "Test score: 0.651\n",
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.666\n",
            "Test score: 0.651\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.650\n",
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.609\n",
            "Test score: 0.650\n",
            "Training batch number 1800 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.651\n",
            "Training batch number 2000 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.652\n",
            "Training batch number 2200 out of 8625\n",
            "Batch score: 0.667\n",
            "Test score: 0.652\n",
            "Training batch number 2400 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.653\n",
            "Training batch number 2600 out of 8625\n",
            "Batch score: 0.652\n",
            "Test score: 0.652\n",
            "Training batch number 2800 out of 8625\n",
            "Batch score: 0.643\n",
            "Test score: 0.651\n",
            "Training batch number 3000 out of 8625\n",
            "Batch score: 0.656\n",
            "Test score: 0.652\n",
            "Training batch number 3200 out of 8625\n",
            "Batch score: 0.660\n",
            "Test score: 0.649\n",
            "Training batch number 3400 out of 8625\n",
            "Batch score: 0.656\n",
            "Test score: 0.651\n",
            "Training batch number 3600 out of 8625\n",
            "Batch score: 0.677\n",
            "Test score: 0.652\n",
            "Training batch number 3800 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.651\n",
            "Training batch number 4000 out of 8625\n",
            "Batch score: 0.691\n",
            "Test score: 0.650\n",
            "Training batch number 4200 out of 8625\n",
            "Batch score: 0.665\n",
            "Test score: 0.653\n",
            "Training batch number 4400 out of 8625\n",
            "Batch score: 0.646\n",
            "Test score: 0.653\n",
            "Training batch number 4600 out of 8625\n",
            "Batch score: 0.668\n",
            "Test score: 0.652\n",
            "Training batch number 4800 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.652\n",
            "Training batch number 5000 out of 8625\n",
            "Batch score: 0.668\n",
            "Test score: 0.652\n",
            "Training batch number 5200 out of 8625\n",
            "Batch score: 0.670\n",
            "Test score: 0.652\n",
            "Training batch number 5400 out of 8625\n",
            "Batch score: 0.657\n",
            "Test score: 0.651\n",
            "Training batch number 5600 out of 8625\n",
            "Batch score: 0.674\n",
            "Test score: 0.651\n",
            "Training batch number 5800 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.651\n",
            "Training batch number 6000 out of 8625\n",
            "Batch score: 0.619\n",
            "Test score: 0.652\n",
            "Training batch number 6200 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.652\n",
            "Training batch number 6400 out of 8625\n",
            "Batch score: 0.634\n",
            "Test score: 0.652\n",
            "Training batch number 6600 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.651\n",
            "Training batch number 6800 out of 8625\n",
            "Batch score: 0.674\n",
            "Test score: 0.651\n",
            "Training batch number 7000 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.652\n",
            "Training batch number 7200 out of 8625\n",
            "Batch score: 0.632\n",
            "Test score: 0.651\n",
            "Training batch number 7400 out of 8625\n",
            "Batch score: 0.642\n",
            "Test score: 0.652\n",
            "Training batch number 7600 out of 8625\n",
            "Batch score: 0.679\n",
            "Test score: 0.653\n",
            "Training batch number 7800 out of 8625\n",
            "Batch score: 0.663\n",
            "Test score: 0.652\n",
            "Training batch number 8000 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.652\n",
            "Training batch number 8200 out of 8625\n",
            "Batch score: 0.625\n",
            "Test score: 0.651\n",
            "Training batch number 8400 out of 8625\n",
            "Batch score: 0.648\n",
            "Test score: 0.652\n",
            "Training batch number 8600 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.652\n",
            "Model saved\n",
            "---------------------- EPOCH 6 ----------------------\n",
            "Training batch number 200 out of 8625\n",
            "Batch score: 0.656\n",
            "Test score: 0.652\n",
            "Training batch number 400 out of 8625\n",
            "Batch score: 0.657\n",
            "Test score: 0.653\n",
            "Training batch number 600 out of 8625\n",
            "Batch score: 0.664\n",
            "Test score: 0.652\n",
            "Training batch number 800 out of 8625\n",
            "Batch score: 0.639\n",
            "Test score: 0.651\n",
            "Training batch number 1000 out of 8625\n",
            "Batch score: 0.685\n",
            "Test score: 0.651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training batch number 1200 out of 8625\n",
            "Batch score: 0.653\n",
            "Test score: 0.651\n",
            "Training batch number 1400 out of 8625\n",
            "Batch score: 0.630\n",
            "Test score: 0.651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training batch number 1600 out of 8625\n",
            "Batch score: 0.649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a52880814d2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training batch number {batchCounter} out of {numBatches}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch score: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test score: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/gdrive/My Drive/Notebooks Colab/MLPModel_e{n + 1}.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \"\"\"\n\u001b[1;32m    970\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 104\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "pSoyLAHbCnAU",
        "outputId": "e5d1f490-2270-4754-c138-e3415b07a7dc"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "metrics.plot_roc_curve(model, xTest, yTest)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_ZbEsafdf7U"
      },
      "source": [
        "with open('/content/gdrive/My Drive/Notebooks Colab/logRegModel_e10.pickle', 'rb') as handle:\n",
        "    model = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "xb5SQbP3dsfG",
        "outputId": "41044794-e53c-40f3-ae9e-1b096b8495c7"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "metrics.plot_roc_curve(model, xTest, yTest)\n",
        "plt.show()\n",
        "xTest.shape\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8921483, 81)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}